{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$\\text{PyTorch}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando imagénes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_images\n",
    "\n",
    "# MNIST path\n",
    "mnist_path = 'data/mnist_raw/'\n",
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
    "\n",
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(np.float32)\n",
    "y_train = y_train_num[:50000].reshape(50000, 1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(np.float64)\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(np.float64)\n",
    "y_test = y_test_num.copy().reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data-x_mean)/x_std\n",
    "\n",
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrando imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import plot_number\n",
    "\n",
    "rand_idx = np.random.randint(len(y_test_num))\n",
    "print(f'numero: {y_test_num[rand_idx]}')\n",
    "plot_number(x_test_num[rand_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando minibaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(x, y, mb_size, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]  \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertimos los arreglos de Numpy as tensores de Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.Tensor(x_train.copy())\n",
    "y_train_tensor = torch.Tensor(y_train.copy())\n",
    "\n",
    "x_val_tensor = torch.Tensor(x_val.copy())\n",
    "y_val_tensor = torch.Tensor(y_val.copy())\n",
    "\n",
    "x_test_tensor = torch.Tensor(x_test.copy())\n",
    "y_test_tensor = torch.Tensor(y_test.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar GPU de estar disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estamos usando: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'estamos usando: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,x,y,mb_size):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    model.eval() #poner el modelo en modo evaluación\n",
    "    model = model.to(device=device) #cargando el modelo en gpu o cpu\n",
    "    with torch.no_grad():\n",
    "        for (xi,yi) in create_minibatches(x,y,mb_size):\n",
    "            #cargamos las variables a la memoria del gpu o cpu\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            scores = model(xi) #mb_size filas por 10 columnas (para este ejemplo)\n",
    "            _,pred = scores.max(dim=1) \n",
    "            num_correct += (pred == yi.squeeze()).sum() #comprimimos yi ya que pred tiene la forma,shape, (mb_size,)\n",
    "            num_total += pred.size(0) #se usa size ya que pred es un tensor, en caso de una arrglo se usa shape\n",
    "        return float(num_correct)/num_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,mb_size,epochs=100):\n",
    "    model = model.to(device=device)\n",
    "    for epoch in range(epochs):\n",
    "        for (xi,yi) in create_minibatches(x_train_tensor,y_train_tensor,mb_size):\n",
    "            model.train() #cambiando a modo entrenamiento\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            scores = model(xi)\n",
    "            #función costo\n",
    "            cost = F.cross_entropy(input=scores,target=yi.squeeze())\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'epoch:{epoch} ,costo:{cost.item()} ,accuracy:{accuracy(model,x_val_tensor,y_val_tensor,mb_size)}')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo usando Sequencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciar modelo\n",
    "hidden1 = 200\n",
    "hidden = 200\n",
    "lr = 1e-4\n",
    "epochs = 20\n",
    "mb_size = 512\n",
    "\n",
    "model1 = nn.Sequential(nn.Linear(in_features=784,out_features=hidden1),nn.ReLU(),\n",
    "                        nn.Linear(in_features=hidden,out_features=10))\n",
    "\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 ,costo:2.3232476711273193 ,accuracy:0.104\n",
      "epoch:1 ,costo:2.2773616313934326 ,accuracy:0.1115\n",
      "epoch:2 ,costo:2.2446045875549316 ,accuracy:0.1205\n",
      "epoch:3 ,costo:2.2635691165924072 ,accuracy:0.1313\n",
      "epoch:4 ,costo:2.259185791015625 ,accuracy:0.1515\n",
      "epoch:5 ,costo:2.224487781524658 ,accuracy:0.1714\n",
      "epoch:6 ,costo:2.2183287143707275 ,accuracy:0.1979\n",
      "epoch:7 ,costo:2.207873821258545 ,accuracy:0.2248\n",
      "epoch:8 ,costo:2.1649234294891357 ,accuracy:0.262\n",
      "epoch:9 ,costo:2.1727452278137207 ,accuracy:0.2936\n",
      "epoch:10 ,costo:2.159405469894409 ,accuracy:0.3264\n",
      "epoch:11 ,costo:2.1295855045318604 ,accuracy:0.3581\n",
      "epoch:12 ,costo:2.106022357940674 ,accuracy:0.3912\n",
      "epoch:13 ,costo:2.1139912605285645 ,accuracy:0.4225\n",
      "epoch:14 ,costo:2.078920841217041 ,accuracy:0.4519\n",
      "epoch:15 ,costo:2.0827581882476807 ,accuracy:0.482\n",
      "epoch:16 ,costo:2.0555546283721924 ,accuracy:0.5083\n",
      "epoch:17 ,costo:2.0384838581085205 ,accuracy:0.5318\n",
      "epoch:18 ,costo:2.033234119415283 ,accuracy:0.5523\n",
      "epoch:19 ,costo:2.0063817501068115 ,accuracy:0.5705\n"
     ]
    }
   ],
   "source": [
    "train(model1,optimizer,mb_size,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5591"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model1, x_test_tensor,  y_test_tensor, mb_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('environment': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e501ee22cc57deeb2360814fd125914d9538f135e6d01a58ac42a717d3f1d7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
