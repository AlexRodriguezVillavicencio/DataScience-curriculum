{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $$\\text{Tarea NLP ML AZ}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ignoramos las comillas dobles quoting\n",
    "dataset = pd.read_csv('./Restaurant_Reviews.tsv', sep='\\t', quoting=3)\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#limpieza\n",
    "corpus = []\n",
    "for i in range(dataset.shape[0]):\n",
    "    review = re.sub('[^a-zA-Z]',' ',dataset.Review[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "#back of word\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "cv = CountVectorizer(max_features=1200)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "X.shape\n",
    "\n",
    "y = dataset.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividimos en datos de entrenamiento y prueba\n",
    "from  sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función de precisión de algoritmos\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "def precision():\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    print('Matriz de confusión:')\n",
    "    print(cm)\n",
    "    print('')\n",
    "    Accuracy = (cm[0][0] + cm[1][1])/len(y_test)\n",
    "    print(f'Accuracy: {round(Accuracy,2)}')\n",
    "    Presicion = (cm[0][0])/(cm[0][0] + cm[1][0])\n",
    "    print(f'Presición: {round(Presicion,2)}')\n",
    "    Recall = (cm[0][0])/(cm[0][0] + cm[0][1])\n",
    "    print(f'Recall: {round(Recall,2)}')\n",
    "    F1Score = (2*Presicion*Recall)/(Presicion+Recall)\n",
    "    print(f'F1 Score: {round(F1Score,2)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Pregunta 1`\n",
    "`Ejecuta los otros algoritmos de clasificación que elaboramos en la\n",
    "Parte 3 - Clasificación, además del que ya he usado en esta última\n",
    "clase de la sección.`\n",
    "\n",
    "#### `Pregunta 2`\n",
    "`Evalúa la eficacia de todos estos modelos. Intenta mejorar la Accuracy\n",
    "(exactitud) obtenida en la clase anterior. Recuerda también que la\n",
    "Accuracy no es su ciente, también hay que mirar otras métricas como\n",
    "por ejemplo`\n",
    "- `Accuracy, la exactitud de la predicción: (TP+TN)/(TP+TN+FP+FN)`\n",
    "- `Precision, medida de la precisión del algoritmo para la clase positiva:\n",
    "TP/(TP+FP)`\n",
    "- `Recall, medida de la completitud del algoritmo: TP/(TP+FN)`\n",
    "- `F1 Score, compromiso entre la precisión y la completitud:\n",
    "2*Precision*Recall/(Precision+Recall)`\n",
    "\n",
    "`Os recuerdo que TP = #Verdaderos Positivos, TN =#Verdaderos\n",
    "Negativos, FP = #Falsos Positivos y FN = #Falsos Negativos`\n",
    "\n",
    "$$ \\displaystyle {\\begin{bmatrix} TP & FN \\\\ FP & TN \\end{bmatrix}} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[81 16]\n",
      " [62 41]]\n",
      "\n",
      "Accuracy: 0.61\n",
      "Presición: 0.57\n",
      "Recall: 0.84\n",
      "F1 Score: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "precision()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[76 21]\n",
      " [38 65]]\n",
      "\n",
      "Accuracy: 0.7\n",
      "Presición: 0.67\n",
      "Recall: 0.78\n",
      "F1 Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "precision()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arboles de Clasifición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[66 31]\n",
      " [35 68]]\n",
      "\n",
      "Accuracy: 0.67\n",
      "Presición: 0.65\n",
      "Recall: 0.68\n",
      "F1 Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "precision()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bosques Aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[74 23]\n",
      " [32 71]]\n",
      "\n",
      "Accuracy: 0.72\n",
      "Presición: 0.7\n",
      "Recall: 0.76\n",
      "F1 Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier \n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=8, criterion=\"entropy\" ,random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "precision()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maquina de Soporte Vectorial (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[74 23]\n",
      " [35 68]]\n",
      "\n",
      "Accuracy: 0.71\n",
      "Presición: 0.68\n",
      "Recall: 0.76\n",
      "F1 Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel=\"linear\", random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "precision()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Pregunta 3`\n",
    "`Intenta otros algoritmos de clasificación que no hemos cubierto en la\n",
    "Parte 3 - Clasificación. Los buenos para NLP incluyen:`\n",
    "- `CART`\n",
    "- `C5.0`\n",
    "- `Máxima Entropía`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CART <> Arboles de desición y Regresión (Skity learn usa una versión optimizada del algoritmo CART)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b96c178e54cac6df8b276c6cdc187592da14953e9b90e9b6c49e854357e283b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
